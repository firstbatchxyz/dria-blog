README.md:
  hash: 0dac128a126400b9bea68d77418da820
  summary: 'Dria is a cutting-edge synthetic data infrastructure designed to enhance
    AI development by balancing data quality, diversity, and complexity through a
    single interface. It offers a framework for creating, managing, and orchestrating
    synthetic data pipelines, utilizing a multi-agent network to synthesize data from
    both web and siloed sources. Key features include massive parallelization and
    compute offloading, allowing users to leverage network resources without personal
    GPU infrastructure, flexible and scalable custom pipelines, and an extensive built-in
    toolset for rapid data generation. Dria also supports creating pipelines that
    enable AI to search for grounding in real-life distributions from web or siloed
    APIs. Ideal for AI development, Dria SDK is available under the MIT License. Keywords:
    synthetic data, AI development, data pipelines, compute offloading, data generation,
    parallelization, scalability.'
cookbook/eval.md:
  hash: f4c8128a044ee4f9539cfbe0fb32af66
  summary: 'This guide provides a comprehensive approach to evaluating Retrieval-Augmented
    Generation (RAG) systems using synthetic data, aimed at enhancing AI-powered question-answering
    applications. It covers setting up a RAG pipeline with key components such as
    embedding model choice, retrieval methods (like BM25 and VectorDB), reranking
    strategies, and answer generation. It demonstrates the use of synthetic data for
    generating diverse question-answer pairs, including multi-hop questions, to effectively
    test and improve RAG system performance. Tools like RAGatouille, Instructor, and
    various Pydantic models are used to streamline the process. The guide also includes
    a detailed evaluation methodology to assess prediction accuracy against ground
    truth, employing advanced AI models to generate and evaluate synthetic datasets.
    Keywords: RAG systems, synthetic data, question-answering, AI, evaluation.'
cookbook/function_calling.md:
  hash: 9c3ae7208d490e525fa054fd52ad558e
  summary: Discover the intricacies of function calling in programming with this comprehensive
    guide that covers utilization, benefits, and best practices. Learn how function
    calling enhances code efficiency and maintainability, a crucial concept in software
    engineering and development. Key topics include optimizing function calls for
    performance, understanding the role of parameters and return values, and implementing
    best practices to streamline development processes. Perfect for anyone looking
    to deepen their understanding of programming fundamentals and improve their software
    development skills.
cookbook/nemotron_qa.md:
  hash: 77d33f36a9f427d50b4ea2b7bcec0ebf
  summary: The article provides a detailed guide on implementing Nvidia's Preference
    Data Pipeline using Dria for generating synthetic preference data and alignment
    training. It highlights the use of Meta's Llama 3.1 405B Instruct for synthetic
    response generation and Nemotron-4 340B Reward for scoring. The implementation
    involves creating a folder structure with specific tasks and prompts, and setting
    up a Dria pipeline with steps for subtopic, question, and answer generation. Key
    components include utilizing Dria's `PipelineBuilder` and `StepTemplate` for workflow
    creation, defining callback methods to manage data flow, and choosing suitable
    AI models. The setup enables efficient machine learning capabilities and synthetic
    data alignment, emphasizing keywords like Nvidia, synthetic data, Dria, machine
    learning, and preference data.
cookbook/patient_dialogues.md:
  hash: 62e46359d39ee0a51515a2058d785811
  summary: This collection focuses on patient dialogues intended for training and
    analysis in healthcare communication. It is designed to enhance patient communication
    skills through applied AI and natural language processing techniques. Key objectives
    include improving healthcare AI systems, advancing dialogue analysis, and facilitating
    medical training. Relevant keywords include patient communication, healthcare
    AI, dialogue analysis, medical training, and natural language processing.
cookbook/preference_data.md:
  hash: 98bfc978b8cab10f2c9bc1008484351c
  summary: Explore the innovative realm of synthetic preference data generation with
    Dria, a cutting-edge tool designed to enhance AI simulations and data modeling.
    Focused on synthetic data, preference modeling, and advanced data generation,
    Dria offers powerful solutions for creating realistic and diverse data sets for
    AI applications. This technology is pivotal for improving AI accuracy and performance
    by simulating varied user preferences, making it an essential resource in the
    field of AI development. Key areas of interest include synthetic data, AI simulations,
    and preference modeling.
example_run.md:
  hash: f86fd5d98e285045529aaa48a5b1870e
  summary: This article provides a script example demonstrating the use of the Dria
    library for asynchronous model batch processing in Python, ideal for machine learning
    workflows. Key points include utilizing the `Dria` client and `MagPie` factory
    along with the `ParallelSingletonExecutor` to manage models like `GPT4O_MINI`,
    `GEMINI_15_FLASH`, and `MIXTRAL_8_7B`. The script showcases how to set up models
    and execute asynchronous batch processing tasks with prompts, such as asking for
    the capitals of France and Germany. Important keywords include Dria library, asynchronous
    processing, batch processing, Python, and machine learning.
factory/clair.md:
  hash: 0eb239913f671f2c12d52f06a3fc24d3
  summary: Clair is an AI-powered educational tool designed to automate solution checking
    and provide detailed feedback for students. It processes student-submitted solutions,
    offers corrections, and includes thorough reasoning to enhance learning. Key features
    include automated feedback, solution correction, and educational enhancement,
    using AI models to improve student understanding. This tool supports categories
    like AI education, solution checking, and student feedback. Clair aims to facilitate
    learning by offering clear, detailed corrections and explanations to help students
    better understand their work.
factory/code_generation.md:
  hash: 1bbc11b0c988971709d6fa216bf8b5ef
  summary: GenerateCode is a software engineering tool that employs Singleton classes
    for dynamic code generation and iteration across multiple programming languages.
    The primary classes, `GenerateCode` and `IterateCode`, efficiently produce code
    based on user instructions, leveraging AI models like `Model.CODER` and `Model.QWEN2_5_CODER_1_5B`
    for optimal results. Users input their code generation requirements, specifying
    the desired programming language and receiving AI-generated code as output. Key
    features include ease of integration for developers seeking automated code creation,
    focusing on software development, AI coding, and the Singleton pattern.
factory/complexity_scorer.md:
  hash: 084060be913b09d7b63edeb4c333816a
  summary: ScoreComplexity is a tool designed to assign complexity scores to a list
    of instructions, aiding in data generation and evaluation tasks. It uses an AI
    scoring model to provide a numerical complexity score for each instruction, helping
    in performance analysis. The service can be integrated into workflows for complexity
    scoring, data generation, and instruction evaluation. The AI model cited in the
    examples is "llama3.1:8b-instruct-fp16." Key applications include analyzing tasks
    for data selection and instruction tuning. Keywords include complexity scoring,
    AI scoring model, instruction evaluation, and data generation.
factory/csv_extender.md:
  hash: 148f3a8e64396981d2bd398255ffbbdd
  summary: CSVExtenderPipeline is a tool designed to enhance data management by generating
    additional rows in CSV files based on existing data. It works by adding new subcategories
    to current categories, allowing users to specify the number of new independent
    values and the number of rows to generate for each value. This automation tool
    is ideal for data generation and management in pipelines, ensuring efficient expansion
    of datasets. Key features include enhancing CSV files, improving data management
    processes, and automating data extension tasks. Keywords include CSV, data management,
    data generation, pipelines, and automation.
factory/evaluate.md:
  hash: 6b626431a16db08d79448938592fe331
  summary: 'The "EvaluatePrediction" is a singleton class designed for assessing the
    quality and accuracy of predicted answers in relation to a specific question and
    context, offering detailed feedback beyond a mere true/false evaluation. Key features
    include accepting inputs like the predicted answer, original question, and context,
    and providing outputs that contain a detailed evaluation, the prediction itself,
    and the AI model used. Primarily utilized in workflows involving prediction evaluation,
    this tool is useful for understanding and improving AI-generated responses, especially
    in data generation processes. Keywords: prediction evaluation, AI, feedback, data
    generation, workflows.'
factory/evolve_complexity.md:
  hash: 5ad5782600da990c1fec4f2a39900606
  summary: EvolveComplexity is a tool designed to transform simple instructions into
    more complex versions while preserving their original intent, making it valuable
    for data generation and AI model enhancement. It operates by taking input instructions
    and evolving them, resulting in a detailed output that maintains the core idea
    but with increased complexity. This is particularly useful for applications in
    AI where varied complexities of instructions are required. Key aspects include
    its integration with datasets like DriaDataset and using AI models such as "qwen2.5:32b-instruct-fp16."
    The tool is highlighted for its application in tasks like instruction evolution
    and data generation. Related resources include WizardLM and various GitHub repositories.
factory/graph_builder.md:
  hash: ba01e2878d10443465b9d72e76a0b094
  summary: GenerateGraph is a versatile AI tool designed for extracting ontological
    relationships from text, aiming to create graph-like structures that illustrate
    concepts and their connections. It processes input to identify and map out the
    relationships between key terms, making it valuable for applications in ontology
    extraction, graph generation, AI relationships, and data science. The tool outputs
    a GraphRelation schema, detailing the conceptual nodes and the relationships (edges)
    between them, using a specified AI model for generation. This capability is pivotal
    for enhancing machine learning and artificial intelligence workflows, offering
    insights into the interconnectedness of concepts such as AI, machine learning,
    and deep learning.
factory/instruction_backtranslation.md:
  hash: eb6981268b14f4f175f0e02adee802fd
  summary: InstructionBacktranslation is a singleton class designed to evaluate instruction-generation
    pairs efficiently for accurate AI responses and data generation. The tool assesses
    an original instruction and its generated text, providing an evaluation score
    and detailed reasoning. Key features include instruction evaluation, backtranslation,
    AI model scoring, and data generation, all crucial for natural language processing
    tasks. The system echoes input details and specifies the AI model used for evaluation.
    It supports data generation with example outputs showcasing a concise evaluation
    process for instruction-generation accuracy. Key references include "Distilabel
    InstructionBacktranslation" and a related research paper on self-alignment using
    instruction backtranslation.
factory/instruction_evolution.md:
  hash: 03b7852e7f8517a0fc4caaf8df2b46de
  summary: EvolveInstruct is a comprehensive solution for transforming AI prompts
    using diverse mutation strategies while maintaining their core intent. Key mutation
    types include FRESH_START, ADD_CONSTRAINTS, DEEPEN, CONCRETIZE, INCREASE_REASONING,
    and SWITCH_TOPIC, which enhance data generation by making prompts more complex,
    specific, or require deeper reasoning. By employing models like "gemma2:9b-instruct-fp16,"
    EvolveInstruct facilitates the creation of nuanced data sets, vital for advancing
    prompt evolution, data generation, and mutation strategies in AI. This tool is
    ideal for enhancing AI capabilities in understanding and responding to complex
    instructions.
factory/iterate_code.md:
  hash: b156ceedbe6278645d67e7155de55b48
  summary: The content describes the "IterateCode Singleton" for enhancing AI-driven
    code generation by iterating over existing code with specified instructions and
    targeting a specific programming language. It highlights the input requirements,
    which include the original code, an instruction for code generation, and the programming
    language. Outputs include the improved code, the original instruction and code,
    and the AI model used. This tool is particularly relevant for software engineering,
    offering benefits in AI optimization, error handling, and streamlined programming.
    The usage is exemplified with Python, demonstrating its application in refining
    code functionality. Key terms include code generation, AI optimization, and programming.
factory/list_extender.md:
  hash: bd7ab654e5d7a62a7bfb3f1a1536d9cf
  summary: ListExtender is a singleton class designed for data generation, specifically
    aimed at enhancing a given list by adding unique and related items while ensuring
    originality and coherence. The primary input is an initial list of strings, and
    the output includes an extended list of combined original and generated items
    along with the AI model used for generation. Keywords include list extension,
    data generation, unique items, related items, and singleton class. The tool is
    particularly useful for expanding datasets in a coherent manner, maintaining relevance
    and diversity in the extended list.
factory/magpie.md:
  hash: 5d30d0250a0dc1813383671b1d9c817c
  summary: MagPie is a singleton template designed for dialogue generation between
    two personas, focusing on conversational exchanges with configurable turns. It
    facilitates AI conversations and persona simulations, enabling structured data
    generation for natural language processing. Key inputs include instructor and
    responder personas and the number of dialogue turns. Outputs consist of a dialogue
    list detailing each exchange, alongside the AI model used. MagPie is useful for
    synthesizing dialogue datasets and ensuring unbiased, fair AI conversations, employing
    techniques for bias mitigation and evaluation. Core concepts include dialogue
    generation, AI persona simulation, data synthesis, and natural language processing.
factory/multihopqa.md:
  hash: 9b6cfe0603ad3c7d4aed619324ded4ca
  summary: MultiHopQuestion is a template designed for generating complex multi-hop
    questions from three document chunks. It creates questions of varying complexity,
    including 1-hop, 2-hop, and 3-hop questions, each accompanied by corresponding
    answers. The template is specifically useful for data generation in natural language
    processing tasks such as question generation and answer prediction, leveraging
    AI models for enhanced performance. This tool is essential for developing datasets
    that require intricate reasoning across multiple documents. Keywords include multi-hop
    questions, question generation, AI models, and natural language processing.
factory/persona.md:
  hash: 8dec4ab50ccb796b646fc05eba03a996
  summary: The "Persona" pipeline is a tool designed for generating character backstories
    and bios using AI models. It is particularly useful for simulations and character
    development scenarios, leveraging persona traits and simulation context to create
    engaging and detailed narratives. Key components include the "PersonaBio" for
    short bios and "PersonaBackstory" for longer narratives. The tool supports character
    development, narrative generation, and backstory creation through simulation descriptions,
    enhancing storytelling in simulations or gaming environments. Keywords include
    Character Development, AI Models, Narrative Generation, and Simulation Tools.
factory/qa.md:
  hash: 989792701423f6519d70e75c43a0e6ab
  summary: 'The "QuestionAnswer" pipeline is an AI-driven workflow designed to generate
    contextually relevant responses using specified personas and structured outputs
    in Python. Key features include the ability to process inputs such as context
    and persona to produce answers aligned with JSON schema, ensuring accurate and
    consistent outputs. The pipeline leverages AI models like GPT-4O to deliver reliable,
    structured data generation for applications in question-answering and data generation.
    This system is particularly useful for creating datasets that adhere to strict
    output schemas, preventing errors like missing keys or invalid enum values. Keywords:
    AI, Python, Question Answer, Data Generation, Structured Outputs, JSON Schema,
    GPT-4O.'
factory/quality_evolution.md:
  hash: 884e9492892acc5f7359d91c82fa6b85
  summary: EvolveQuality is an AI-driven tool designed for enhancing text responses
    by applying methods focused on improving helpfulness, relevance, depth, creativity,
    and detail levels. It serves as a singleton template that refines original responses,
    utilizing AI models to produce more refined and high-quality outputs. Key features
    include multiple evolution methods like HELPFULNESS, RELEVANCE, DEEPENING, CREATIVITY,
    and DETAILS, which transform basic responses into comprehensive and user-friendly
    content. This tool is valuable for data generation, improving the overall quality
    and effectiveness of text-based communications.
factory/search.md:
  hash: 97b97467056ef72f805880e2390303f4
  summary: SearchWeb is a singleton tool that simplifies web searches by providing
    structured results with customizable queries in different languages and limits
    on the number of results (1-25, default is 5). This Python-based solution is especially
    useful for data generation, as each result includes the query, link, snippet,
    and title of web pages. Its integration with data generation frameworks like Dria
    allows users to effortlessly generate structured datasets. Important keywords
    related to this tool include SearchWeb, web search, data generation, singleton
    design pattern, Python, and structured web results.
factory/self_instruct.md:
  hash: 5a7d27c7872fdba5c02c75b4686e297d
  summary: 'SelfInstruct is an automated tool designed to enhance AI testing and training
    by generating user queries based on specific criteria and context. It streamlines
    the creation of relevant instructions for AI applications, improving data generation
    efficiency. Key features include specifying the number of queries needed, the
    criteria for their generation, and the applicable context, with the output being
    a list of generated instructions and the model used. SelfInstruct is ideal for
    automating AI query generation and data generation, making it a valuable resource
    for AI training and development. Keywords: AI query generation, automation, data
    generation, SelfInstruct, training AI.'
factory/semantic_triplet.md:
  hash: 4f8e2cc66cea7c7c0c8a6fe3ca31909d
  summary: 'The article introduces the "SemanticTriplet" task, a specialized AI application
    designed for generating semantic triplets in JSON format with specified similarity
    scores between textual units. SemanticTriplet accommodates various configurations,
    allowing users to specify the type of text unit (e.g., sentence, paragraph), language,
    similarity scores, and difficulty level. It employs AI models like GEMINI_15_FLASH
    to produce organized JSON outputs featuring three distinct text units: S1, S2,
    and S3, each with defined semantic relationships. This tool is ideal for applications
    in natural language processing, semantic similarity assessments, and AI-driven
    text generation, making it a valuable resource for projects demanding precise
    semantic analysis. Key terms include semantic similarity, JSON generation, NLP
    tasks, and AI models.'
factory/simple.md:
  hash: 5933cfdbbb5b6c7510e2c1854a1f13f0
  summary: The "Simple" template is designed for basic text generation workflows,
    making use of customizable prompts and specified models to produce text outputs.
    Key features include being a singleton template facilitating data generation,
    and its implementation involves providing a prompt as input to generate corresponding
    text. Outputs of this process include the original prompt, the generated text,
    and the model used for generation. The template is ideal for straightforward text
    generation tasks and can be integrated into datasets like "DriaDataset" for efficient
    and customizable text generation. Core keywords include text generation, singleton
    template, prompts, workflow, and data generation.
factory/subtopic.md:
  hash: b7d26e73278d9ec0b6c92b2263d79f00
  summary: GenerateSubtopics is an AI tool designed to enhance data generation workflows
    by creating relevant subtopics from a main topic. This Rust programming-based
    tool processes a given topic and uses AI to generate logical and detailed subtopics,
    facilitating structured data creation. Key elements include its inputs and outputs,
    where users provide a main topic, and the tool outputs the original topic alongside
    its generated subtopics with the AI model used. It is especially useful in AI
    generation, subtopic development, and data management workflows, employing advanced
    models like "anthropic/claude-3-5-haiku" to ensure precision and relevance. The
    tool exemplifies cutting-edge solutions in automatic content generation and topic
    outlining, optimizing both workflow efficiency and data depth.
factory/validate.md:
  hash: 73db36e32035caf961d9ab94c41cb198
  summary: ValidatePrediction is a singleton class designed for AI validation, focusing
    on comparing and verifying AI-generated predictions against correct answers. It
    utilizes contextual and semantic analysis to provide a boolean validation result,
    indicating whether the prediction matches the correct answer. Key features include
    handling inputs of predicted answers and correct answers, and producing outputs
    that include both the original answers and validation results, as well as the
    AI model used. The class is particularly useful for AI validation, prediction
    comparison, data generation, and ensuring semantic accuracy in AI models.
factory/web_multi_choice.md:
  hash: e462d28ad81c9acf2c426a04ba1695ed
  summary: WebMultiChoice is a singleton task designed to answer multiple-choice questions
    using advanced web search and evaluation methods, primarily within a medical context.
    The workflow includes generating a web search query, scraping the content from
    a selected URL, and evaluating notes to determine the best answer. Key features
    include task automation, AI evaluation, and the use of models like QWEN2_5_7B_FP16
    to ensure accurate responses. This tool is particularly useful for applications
    involving medical multiple-choice questions and AI-driven decision-making.
how-to/batches.md:
  hash: 9b31abb156376ea916e4cf9815ea50a7
  summary: This guide explains how to utilize Batches with the ParallelSingletonExecutor
    in Python for concurrent execution of multiple instructions using Dria. Key concepts
    include creating a Dria client, a Singleton task, and employing the ParallelSingletonExecutor
    to run tasks in parallel. Key points include setting up models like Model.QWEN2_5_7B_OR
    and Model.LLAMA_3_1_8B_OR, using the load_instructions method for task input,
    and running them asynchronously with asyncio. Important keywords are parallel
    execution, concurrency, Python, Dria, Batches, ParallelSingletonExecutor, and
    Singleton task.
how-to/data_enrichment.md:
  hash: 2e1b8211bd87f8c7b0a3aa31f6518de4
  summary: Dria's data enrichment tools, like the `enrich` method, enhance datasets
    by generating new fields, enabling richer data for analytics and machine learning.
    Users define a schema using Pydantic models, create prompts to guide data transformation,
    and then apply these on datasets. This process is illustrated through examples,
    such as text summarization and sentiment analysis. Key usage cases include enriching
    customer feedback and enhancing text corpora with metadata, thereby supporting
    more efficient data processing and improved holistic understanding. Key terms
    include data enrichment, machine learning, analytics, AI toolkit, and data processing.
how-to/data_generators.md:
  hash: 59f7046dae5d5d8aa01f96f70b993606
  summary: 'The DatasetGenerator in Dria is a robust tool designed for seamless dataset
    generation and transformation, supporting both prompt-based and singleton-based
    workflows. Key features include parallel execution, automatic schema validation,
    and support for multiple models, enhancing AI workflows in Python. It simplifies
    data creation through instructions and prompts or pre-built singleton workflows,
    with flexible model configurations ranging from single to multiple and pipeline
    models. This tool is ideal for tasks involving dataset generation, data transformation,
    and AI process automation. Keywords: Dataset Generation, Data Transformation,
    AI Workflows, Dria, Python, Data Generation Tool.'
how-to/dria_datasets.md:
  hash: d11de22a276ac10133e3704c9666b973
  summary: The `DriaDataset` class is a core component of Dria's data generation framework,
    facilitating efficient data management and persistence across various formats,
    including JSON, CSV, and integration with Hugging Face datasets. It supports flexible
    initialization, allowing users to start with an empty dataset or incorporate existing
    data for augmentation or as instructions. Key features include schema validation
    for data consistency, structured handling of complex datasets, and comprehensive
    import/export options for compatibility with machine learning and data processing
    tasks. The `DriaDataset` ensures that all generated data, intermediate steps,
    and failed attempts are systematically saved, enabling robust dataset management
    and preparation.
how-to/dria_datasets_exports.md:
  hash: 244f1a866727dc82fc5834e5e7901b1e
  summary: 'The content provides a comprehensive guide on exporting data from DriaDataset
    in various formats suitable for model training, including TRL-ready formats compatible
    with HuggingFace''s TRL framework. Key functionalities include exporting data
    to pandas DataFrame, JSON, and JSONL formats, as well as preparing data for specific
    training setups using the `Formatter` class. The guide outlines multiple format
    types and subtypes like LANGUAGE_MODELING and PROMPT_COMPLETION, with detailed
    steps for converting data into training-ready formats using ConversationMapping
    and FieldMapping. This seamless integration facilitates plug-n-play with HuggingFace''s
    TRL trainers, such as PPOTrainer and SFTTrainer, making it a valuable resource
    for data export and model training processes in AI development. Keywords: DriaDataset,
    data export, TRL-ready formats, HuggingFace TRL, model training, JSONL, pandas
    DataFrame.'
how-to/formatting.md:
  hash: c8b6db816d92cc79c584831b874afd3e
  summary: "The article introduces the `Formatter` class, a tool designed to convert\
    \ datasets into training-ready formats for various AI models, particularly those\
    \ developed by Dria Network. It outlines the supported format types\u2014Standard\
    \ and Conversational\u2014and their subtypes, such as LANGUAGE_MODELING and PROMPT_COMPLETION.\
    \ The piece includes detailed instructions for importing necessary modules and\
    \ creating mappings for data key conversion. It emphasizes the Formatter's compatibility\
    \ with HuggingFace's TRL framework, facilitating seamless integration by matching\
    \ expected dataset formats for different trainers. Key concepts include data formatting,\
    \ AI training, the Dria Network, and integration with HuggingFace."
how-to/functions.md:
  hash: a73b04bd3272fb9f33bce55215d9eb90
  summary: The article provides an in-depth guide on implementing built-in and custom
    functions in Dria workflows to enhance automation and workflow efficiency. It
    covers Dria's built-in tools and how to utilize the `Operator.FUNCTION_CALLING`
    to execute these tools, with an example of retrieving stock prices. It also discusses
    creating custom functions using `CustomTool` and `HttpRequestTool` for tasks not
    natively supported by Dria. The guide includes detailed examples, such as a custom
    sum calculator and a tool for fetching cryptocurrency prices from an API, demonstrating
    how to integrate these tools into workflows. Key concepts include workflow automation,
    custom functions, Python, and API integration with Dria.
how-to/models.md:
  hash: 421f1f54cab1a258625da6e401986a07
  summary: "Explore the diverse range of AI models available on the Dria Network,\
    \ including popular options like Nous, Phi3, and Llama variations, each available\
    \ in various quantized formats. The network hosts models from leading tech companies\
    \ such as Microsoft, Google, Meta, and Alibaba, with different configurations\
    \ like fp16 and quantized formats ranging from q4 to q8. With options like Microsoft's\
    \ Phi3 Medium and Mini, Google's Gemma2, Meta's Llama3.x, and Alibaba's Qwen2.5,\
    \ the Dria Network caters to different AI and machine learning needs. These models\
    \ are designed for various applications, from coding to complex problem-solving,\
    \ providing an extensive toolkit for researchers and developers. Explore powerful\
    \ models like OpenAI's GPT-4 Turbo, Deepseek Coder, and NVIDIA\u2019s Nemotron,\
    \ as well as OpenRouter's extensive range customizable for diverse solutions.\
    \ Key categories include AI models, machine learning, and specific models (Nous,\
    \ Phi3, Llama, Qwen) to appeal to keywords pertinent in the AI industry."
how-to/pipelines.md:
  hash: 249b08dacf1d72dd88898cc3edd68d1f
  summary: The article provides a comprehensive guide on creating efficient data pipelines
    using asynchronous workflows, focusing on generating complex outputs through parallel
    execution. Key elements include understanding pipelines as sequences of workflows,
    illustrated with a practical example of generating question-answer pairs using
    NVIDIA's synthetic preference data tool. It explains how to implement steps in
    a pipeline using the `Pipeline` class, connect them through `PipelineBuilder`,
    and leverage built-in callbacks such as `scatter`, `broadcast`, and `aggregate`
    to manage workflow execution. The content targets data engineering, async processing,
    and workflow optimization involving tools like Dria and Meta's Llama model.
how-to/prompters.md:
  hash: c60ff92ce96eeacb703c73288e8e841f
  summary: The article provides a guide on using the `Prompt` class with Pydantic
    for generating structured outputs in Python, emphasizing its application in prompt
    engineering and data generation. It details the process of defining output schemas
    using Pydantic models, creating datasets with `DriaDataset`, and utilizing the
    `Prompt` class to build structured prompts. The guide also shows how to use `DatasetGenerator`
    for executing prompts with language models like GPT-4. Core keywords include Pydantic,
    data generation, Python, prompt engineering, and Dria. The guide is tailored for
    creating datasets and generating structured outputs efficiently.
how-to/selecting_models.md:
  hash: 9967fdcfa39d60d027706b28fa2b6e9c
  summary: The article discusses the process of selecting and assigning AI models
    for task execution within the Dria Network, a network of large language models
    (LLMs). It emphasizes using the `Model` enum to choose specific models for tasks
    and explains how the `DatasetGenerator.generate()` function assigns these models
    for execution. The Dria Network allows asynchronous task execution on available
    nodes running desired models, supports tasks across multiple models for comparative
    purposes, and provides different options for selecting models based on their size
    or provider. Key keywords include Dria Network, model selection, task management,
    AI models, LLM, and DatasetGenerator.
how-to/singletons.md:
  hash: 40bc5d4ade61ed05688062a21be0f8ae
  summary: The content provides an in-depth exploration of using Singletons in Dria
    for task automation, specifically focusing on leveraging Pydantic models for input
    validation and output formatting. Singletons are described as pre-built task templates
    designed to handle specific tasks, with the Dria Factory offering ready-to-use
    Singletons for various scenarios. The guide walks through creating a custom Singleton,
    including defining input fields, output schemas, and implementing workflow and
    callback methods. It emphasizes the flexibility of custom Singletons to adapt
    Dria Network for diverse problems, with detailed examples and code snippets illustrating
    the process. Key topics include task automation, AI workflows, Pydantic models,
    and the Dria platform.
how-to/structured_outputs.md:
  hash: 13e4594891fb8dd812b19e228ec802ce
  summary: The document discusses the concept of structured outputs in AI models,
    focusing on ensuring valid JSON responses by adhering to a predefined JSON Schema.
    It highlights the use of OpenAI's structured outputs feature, which prevents the
    model from omitting required keys or generating invalid enum values. Dria Network
    supports structured outputs for AI providers such as OpenAI, Gemini, and Ollama,
    but only for models capable of function calling. The process involves providing
    a schema to a `WorkflowBuilder` instance in the Dria SDK, which then facilitates
    the workflow management. Key terms include structured outputs, JSON Schema, workflow
    management, Dria Network, and AI model validation.
how-to/tasks.md:
  hash: 060e8262ed2e8975152cf818033c7967
  summary: 'Explore the Dria network''s task management system, focusing on the execution,
    features, and lifecycle of tasks for effective workflow management. Tasks in the
    Dria network are asynchronous units of work executed by nodes, allowing scalability
    and model selection flexibility. Key features include asynchronous execution,
    model selection, and result retrieval. The lifecycle includes creation, publication,
    execution, and completion. Utilize Dria''s SDK for seamless task integration and
    scalability in operations, leveraging tools, memory, and AI models. Keywords:
    Dria, tasks, workflows, asynchronous execution, AI models, task lifecycle, scalability.'
how-to/workflows.md:
  hash: 3e6e0c0e73720dcda1e5a5efdcf76e6e
  summary: This article guides users on creating custom workflows within the Dria
    Network, utilizing Large Language Models (LLMs) and memory operations for efficient
    task execution. It explains how workflows break down complex tasks into smaller
    steps that read from and write to memory, enabling inter-step communication. The
    Dria SDK's `dria_workflows` package simplifies the process with tools like `WorkflowBuilder`
    for setting configurations, defining steps, and managing flows with conditions.
    Key components of workflows include managing execution parameters with limits
    on steps, time, and token usage to prevent excessive resource use. The article
    also provides a detailed example workflow involving random variable generation
    and validation. Key tags include Dria Network, Workflows, Large Language Models,
    Python SDK, and Task Automation.
installation.md:
  hash: 44f3163b627d4ced34fa35b5b63fd43c
  summary: 'Learn how to install the Dria SDK for Python on MacOS with this comprehensive
    guide. The SDK requires Python 3.10 or higher and can be installed within a new
    conda environment. Installation includes steps to resolve common issues like coincurve
    and GCC-related errors, and provides troubleshooting tips for tkinter issues on
    MacOS. Access to the Dria Network, currently in alpha, is managed through RPCs,
    with no cost involved in generating data. Contribute to the network by running
    a node, and find additional resources on setting up data pipelines via the Dria
    cookbook. For any unresolved issues, seek assistance on their Discord channel.
    Keywords: Dria SDK, Python installation, MacOS setup, coincurve issues, tkinter
    troubleshooting, data generation.'
modules/structrag.md:
  hash: b50e1f1d561a646c95bcb2de95e308da
  summary: Explore the innovative **StructRAG framework**, a cutting-edge retrieval-augmented
    generation (RAG) approach that enhances large language models (LLMs) for knowledge-intensive
    reasoning tasks. By addressing scattered and noisy information, StructRAG employs
    cognitive-inspired techniques to automatically structure and optimize information
    for improved accuracy. It restructures documents into optimal formats and conducts
    inference on this structured data, achieving state-of-the-art results in various
    complex tasks. The framework involves modules like **StructRAGSynthesize** for
    initial document structuring, **StructRAGSimulate** for response generation, and
    **StructRAGJudge** for validating the relevance and correctness of solutions.
    Key topics include **LLMs**, **AI**, **data structuring**, and **knowledge reasoning**.
modules/structrag2.md:
  hash: 20342250e0c7a6c94f81b09e48dcb316
  summary: 'The content discusses StructRAG, a hybrid approach designed to enhance
    reasoning in large language models (LLMs) through knowledge restructuring. It
    introduces the concept of using a Hybrid Router to determine the format of structured
    information, utilizing tools like StructRAGGraph, StructRAGCatalogue, StructRAGAlgorithm,
    and StructRAGTable within Python code to evaluate and score task complexity. The
    methodology aims to boost knowledge-intensive reasoning by reorganizing information
    at inference time. Key terms include StructRAG, knowledge restructuring, hybrid
    router, LLM, and machine learning. The approach is detailed in the referenced
    research paper "StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via
    Inference-time Hybrid Information Structurization."'
node.md:
  hash: 2b8e3a2fffe37bf7e147b4938bce8121
  summary: This guide provides a quick setup for running a node on Dria, a decentralized
    network for AI collaboration created by FirstBatch. It emphasizes that no wallet
    activity is required and the setup is completed in minutes. Key steps include
    downloading the launcher from the Dria website, running it, entering your ETH
    wallet private key, and selecting a model to serve. Additional functionalities
    can be accessed by entering API keys. Users are encouraged to follow Dria and
    FirstBatch on social media and star their GitHub repo. It is emphasized to refer
    to official guides for optimal results.
quickstart.md:
  hash: 4a8ebffdab241842500ad217dce82342
  summary: This guide provides a quick start for using the Dria SDK to generate tweets
    utilizing Large Language Models (LLMs). The process involves setting up a dataset
    with a defined schema, creating a dataset generator, and defining both instructions
    and prompts to execute. Users can follow these steps to effortlessly generate
    tweets using models such as GPT4O, with results stored in a local database. Key
    components include Dria SDK, data generation, tweet generation, and the use of
    LLMs. Note that during the initial phase, network capacity and data generation
    volumes are limited.
